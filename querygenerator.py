import os
import numpy as np
import pandas as pd


DATA_PATH = 'data'


def merge(targets):
    """Aggregator for merging equal queries generated by different
    classes and/or samples
    """
    if len(targets) > 1:
        ret = set()
        for x in targets:
            ret = ret.union(set(x))
        return ','.join(sorted(ret))
    return ','.join(sorted(targets.iloc[0]))

def mulan():
    DATASETS = ('birds',
                'birds-test',
                'birds-train',
                'CAL500',
                'emotions',
                'emotions-test',
                'emotions-train',
                'mediamill',
                'mediamill-test',
                'mediamill-train',
                'yeast',
                'yeast-test',
                'yeast-train')


    SAMPLES_PER_ATTRIBUTE = 10 # how many queries will be produced per attribute
    MINIMUM_EXAMPLE_COUNT = 6 # ignores attribute if there's less than this amount of examples
    RATIO_OF_SAMPLE = 0.4 # 40% of sample size becomes query and 60% are valid targets
    MAXIMUM_SAMPLE_SIZE = 12 # maximum amount of examples used for querying


    for ds in DATASETS:
        df_Y = pd.read_csv(os.path.join(DATA_PATH, ds + '_Y.csv'))
        queries = []
        targets = []
        
        for attr in df_Y.columns:
            valid_indices = np.nonzero(df_Y[attr])[0]
            size = len(valid_indices)
            if size >= MINIMUM_EXAMPLE_COUNT:
                sample_size = min(int(size * RATIO_OF_SAMPLE), 12)
                for _ in range(SAMPLES_PER_ATTRIBUTE):
                    np.random.shuffle(valid_indices)
                    query = ','.join(map(str, sorted(valid_indices[:sample_size])))
                    target = ','.join(map(str, sorted(valid_indices[sample_size:])))
                    queries.append(query)
                    targets.append(target)
        
        df_query = pd.DataFrame({'query': queries, 'target': targets}).drop_duplicates()
        
        unique_queries = len(df_query['query']) == df_query['query'].nunique()
        
        if not unique_queries:
            df_query = df_query.groupby(by='query').aggregate(merge).reset_index()
        
        unique_queries = len(df_query['query']) == df_query['query'].nunique() 
        assert unique_queries
        
        df_query.to_csv(os.path.join(DATA_PATH, ds + '_query.csv'), index=False)


def cnae():
    SAMPLES_PER_CLASS = 50
    MINIMUM_EXAMPLE_COUNT = 6
    RATIO_OF_SAMPLE = 0.4
    MAXIMUM_SAMPLE_SIZE = 12

    df = pd.read_csv(os.path.join(DATA_PATH, 'CNAE-9.data'), header=None)
    queries = []
    targets = []

    for cls in df[0].unique():
        valid_indices = df.index[df[0] == cls].tolist()
        size = len(valid_indices)

        if size >= MINIMUM_EXAMPLE_COUNT:
            sample_size = min(int(size * RATIO_OF_SAMPLE), MAXIMUM_SAMPLE_SIZE)
            for _ in range(SAMPLES_PER_CLASS):
                np.random.shuffle(valid_indices)
                query = ','.join(map(str, sorted(valid_indices[:sample_size])))
                target = ','.join(map(str, sorted(valid_indices[sample_size:])))
                queries.append(query)
                targets.append(target)

    df_query = pd.DataFrame({'query': queries, 'target': targets}).drop_duplicates()
    unique_queries = len(df_query['query']) == df_query['query'].nunique()

    if not unique_queries:
        df_query = df_query.groupby(by='query').aggregate(merge).reset_index()

    unique_queries = len(df_query['query']) == df_query['query'].nunique()
    assert unique_queries

    df_query.to_csv(os.path.join(DATA_PATH, 'CNAE-9_query.csv'), index=False)


def synthetics():
    DATASETS = ('sparsebinary', 'densebinary', 'sparseinteger', 'denseinteger', 'hugebinary', 'hugeinteger')
    
    SAMPLES_PER_CLASS = 50
    MINIMUM_EXAMPLE_COUNT = 6
    RATIO_OF_SAMPLE = 0.4
    MAXIMUM_SAMPLE_SIZE = 12

    for ds in DATASETS:
        df = pd.read_csv(os.path.join(DATA_PATH, ds + '.csv'))
        queries = []
        targets = []

        for cls in df['target'].unique():
            valid_indices = df.index[df['target'] == cls].tolist()
            size = len(valid_indices)

            if size >= MINIMUM_EXAMPLE_COUNT:
                sample_size = min(int(size * RATIO_OF_SAMPLE), MAXIMUM_SAMPLE_SIZE)
                for _ in range(SAMPLES_PER_CLASS):
                    np.random.shuffle(valid_indices)
                    query = ','.join(map(str, sorted(valid_indices[:sample_size])))
                    target = ','.join(map(str, sorted(valid_indices[sample_size:])))
                    queries.append(query)
                    targets.append(target)

        df_query = pd.DataFrame({'query': queries, 'target': targets}).drop_duplicates()
        unique_queries = len(df_query['query']) == df_query['query'].nunique()

        if not unique_queries:
            df_query = df_query.groupby(by='query').aggregate(merge).reset_index()

        unique_queries = len(df_query['query']) == df_query['query'].nunique()
        assert unique_queries

        df_query.to_csv(os.path.join(DATA_PATH, ds + '_query.csv'), index=False)


def main():
    np.random.seed(42)
    mulan()
    cnae()
    synthetics()


if __name__ == '__main__':
    main()
